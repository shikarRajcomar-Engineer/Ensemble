{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DR Training Aug Only.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+bgf8jmnWdvHF15/IzLNC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikarRajcomar-Engineer/Ensemble/blob/master/DR_Training_Aug_Only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAl6U08jDFxW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr7qIJwjCdhX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iPBPO9MN6qH",
        "outputId": "a5e40f1b-89f4-4f5e-fa51-1ffd01574f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtsQ-d8SvoIu"
      },
      "source": [
        "# Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teM_sn5eZ3vs"
      },
      "source": [
        "import pandas as pd\n",
        "%tensorflow_version 2.x\n",
        "path='/content/drive/My Drive/B3 MSC DR Dataset/'      \n",
        "Results=pd.DataFrame([])\n",
        "Results1=pd.DataFrame([])\n",
        "Results2=pd.DataFrame([])\n",
        "Results3=pd.DataFrame([])\n",
        "Results4=pd.DataFrame([])\n",
        "Results5=pd.DataFrame([])\n",
        "Results6=pd.DataFrame([])\n",
        "\n",
        "aResults=pd.DataFrame([])\n",
        "aResults1=pd.DataFrame([])\n",
        "aResults2=pd.DataFrame([])\n",
        "aResults3=pd.DataFrame([])\n",
        "aResults4=pd.DataFrame([])\n",
        "aResults5=pd.DataFrame([])\n",
        "aResults6=pd.DataFrame([])\n",
        "\n",
        "bResults=pd.DataFrame([])\n",
        "bResults1=pd.DataFrame([])\n",
        "bResults2=pd.DataFrame([])\n",
        "bResults3=pd.DataFrame([])\n",
        "bResults4=pd.DataFrame([])\n",
        "bResults5=pd.DataFrame([])\n",
        "bResults6=pd.DataFrame([])\n",
        "\n",
        "cResults=pd.DataFrame([])\n",
        "cResults1=pd.DataFrame([])\n",
        "cResults2=pd.DataFrame([])\n",
        "cResults3=pd.DataFrame([])\n",
        "cResults4=pd.DataFrame([])\n",
        "cResults5=pd.DataFrame([])\n",
        "cResults6=pd.DataFrame([])\n",
        "\n",
        "dResults=pd.DataFrame([])\n",
        "dResults1=pd.DataFrame([])\n",
        "dResults2=pd.DataFrame([])\n",
        "dResults3=pd.DataFrame([])\n",
        "dResults4=pd.DataFrame([])\n",
        "dResults5=pd.DataFrame([])\n",
        "dResults6=pd.DataFrame([])\n",
        "\n",
        "eResults=pd.DataFrame([])\n",
        "eResults1=pd.DataFrame([])\n",
        "eResults2=pd.DataFrame([])\n",
        "eResults3=pd.DataFrame([])\n",
        "eResults4=pd.DataFrame([])\n",
        "eResults5=pd.DataFrame([])\n",
        "eResults6=pd.DataFrame([])\n",
        "\n",
        "fResults=pd.DataFrame([])\n",
        "fResults1=pd.DataFrame([])\n",
        "fResults2=pd.DataFrame([])\n",
        "fResults3=pd.DataFrame([])\n",
        "fResults4=pd.DataFrame([])\n",
        "fResults5=pd.DataFrame([])\n",
        "fResults6=pd.DataFrame([])\n",
        "\n",
        "gResults=pd.DataFrame([])\n",
        "gResults1=pd.DataFrame([])\n",
        "gResults2=pd.DataFrame([])\n",
        "gResults3=pd.DataFrame([])\n",
        "gResults4=pd.DataFrame([])\n",
        "gResults5=pd.DataFrame([])\n",
        "gResults6=pd.DataFrame([])\n",
        "\n",
        "hResults=pd.DataFrame([])\n",
        "hResults1=pd.DataFrame([])\n",
        "hResults2=pd.DataFrame([])\n",
        "hResults3=pd.DataFrame([])\n",
        "hResults4=pd.DataFrame([])\n",
        "hResults5=pd.DataFrame([])\n",
        "hResults6=pd.DataFrame([])\n",
        "\n",
        "\n",
        "Dataset=['SP_the_wave_Training Aug Only120','SP_udnie_Training Aug Only120']\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtxIqFgrOCO1"
      },
      "source": [
        "# Dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoQeLdNkszBc",
        "outputId": "4448b5d2-2b34-4de0-ab94-8f18bbe8ce91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "\n",
        "\n",
        "\n",
        "batch_size=192\n",
        "steps=100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# fix random seed for reproducibility\n",
        "\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "            \n",
        "      datagen = ImageDataGenerator(rescale=1./255)\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['No Aug','No Aug']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "\n",
        "\n",
        "Results=Results.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.397255</td>\n",
              "      <td>0.199076</td>\n",
              "      <td>0.584483</td>\n",
              "      <td>0.474761</td>\n",
              "      <td>0.396564</td>\n",
              "      <td>0.316944</td>\n",
              "      <td>49.670519</td>\n",
              "      <td>44.610582</td>\n",
              "      <td>49.97579</td>\n",
              "      <td>44.403143</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.351139</td>\n",
              "      <td>0.296360</td>\n",
              "      <td>0.440323</td>\n",
              "      <td>0.460104</td>\n",
              "      <td>0.337175</td>\n",
              "      <td>0.304363</td>\n",
              "      <td>49.670519</td>\n",
              "      <td>44.610582</td>\n",
              "      <td>49.97579</td>\n",
              "      <td>44.403143</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.397255       0.199076  0.584483    0.474761  0.396564      0.316944   \n",
              "1   0.351139       0.296360  0.440323    0.460104  0.337175      0.304363   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var     aug  \\\n",
              "0  49.670519     44.610582      49.97579         44.403143  No Aug   \n",
              "1  49.670519     44.610582      49.97579         44.403143  No Aug   \n",
              "\n",
              "                            dataset  \n",
              "0  SP_the_wave_Training Aug Only120  \n",
              "1  SP_the_wave_Training Aug Only120  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXwiJXlgszB2",
        "outputId": "9cacc698-d656-4537-9c47-202083397024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['HorizontalFlip','HorizontalFlip']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "Results1=Results1.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results1)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.189624</td>\n",
              "      <td>0.232316</td>\n",
              "      <td>0.370690</td>\n",
              "      <td>0.456359</td>\n",
              "      <td>0.250702</td>\n",
              "      <td>0.30745</td>\n",
              "      <td>38.093525</td>\n",
              "      <td>46.752129</td>\n",
              "      <td>49.352977</td>\n",
              "      <td>42.306231</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.384074</td>\n",
              "      <td>0.200221</td>\n",
              "      <td>0.616129</td>\n",
              "      <td>0.470835</td>\n",
              "      <td>0.435281</td>\n",
              "      <td>0.30423</td>\n",
              "      <td>38.093525</td>\n",
              "      <td>46.752129</td>\n",
              "      <td>49.352977</td>\n",
              "      <td>42.306231</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.189624       0.232316  0.370690    0.456359  0.250702       0.30745   \n",
              "1   0.384074       0.200221  0.616129    0.470835  0.435281       0.30423   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var             aug  \\\n",
              "0  38.093525     46.752129     49.352977         42.306231  HorizontalFlip   \n",
              "1  38.093525     46.752129     49.352977         42.306231  HorizontalFlip   \n",
              "\n",
              "                            dataset  \n",
              "0  SP_the_wave_Training Aug Only120  \n",
              "1  SP_the_wave_Training Aug Only120  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AncgPCnLszCG",
        "outputId": "74ba63f9-4a0f-41a4-f808-f987c9b9a5cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(vertical_flip=True)\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['VerticalFlip','VerticalFlip']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "Results2=Results2.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results2)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.405741</td>\n",
              "      <td>0.205036</td>\n",
              "      <td>0.674138</td>\n",
              "      <td>0.351166</td>\n",
              "      <td>0.502826</td>\n",
              "      <td>0.252540</td>\n",
              "      <td>62.347742</td>\n",
              "      <td>37.355355</td>\n",
              "      <td>49.089646</td>\n",
              "      <td>28.641294</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.446449</td>\n",
              "      <td>0.242040</td>\n",
              "      <td>0.375806</td>\n",
              "      <td>0.349803</td>\n",
              "      <td>0.361692</td>\n",
              "      <td>0.244029</td>\n",
              "      <td>62.347742</td>\n",
              "      <td>37.355355</td>\n",
              "      <td>49.089646</td>\n",
              "      <td>28.641294</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.405741       0.205036  0.674138    0.351166  0.502826      0.252540   \n",
              "1   0.446449       0.242040  0.375806    0.349803  0.361692      0.244029   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var           aug  \\\n",
              "0  62.347742     37.355355     49.089646         28.641294  VerticalFlip   \n",
              "1  62.347742     37.355355     49.089646         28.641294  VerticalFlip   \n",
              "\n",
              "                            dataset  \n",
              "0  SP_the_wave_Training Aug Only120  \n",
              "1  SP_the_wave_Training Aug Only120  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixlQV01szCU",
        "outputId": "0359022f-5430-4267-ff84-c33cb21a6d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(rotation_range=(random.randrange(0,360,30)))\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['Rotate','Rotate']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "Results3=Results3.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results3)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.437613</td>\n",
              "      <td>0.051906</td>\n",
              "      <td>0.431034</td>\n",
              "      <td>0.235457</td>\n",
              "      <td>0.398664</td>\n",
              "      <td>0.191575</td>\n",
              "      <td>59.662192</td>\n",
              "      <td>26.636895</td>\n",
              "      <td>63.846912</td>\n",
              "      <td>18.704849</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>51.558751</td>\n",
              "      <td>62.732172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.498888</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.525806</td>\n",
              "      <td>0.223456</td>\n",
              "      <td>0.492386</td>\n",
              "      <td>0.090576</td>\n",
              "      <td>59.662192</td>\n",
              "      <td>26.636895</td>\n",
              "      <td>63.846912</td>\n",
              "      <td>18.704849</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>51.558751</td>\n",
              "      <td>62.732172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.437613       0.051906  0.431034    0.235457  0.398664      0.191575   \n",
              "1   0.498888       0.036000  0.525806    0.223456  0.492386      0.090576   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var     aug  \\\n",
              "0  59.662192     26.636895     63.846912         18.704849  Rotate   \n",
              "1  59.662192     26.636895     63.846912         18.704849  Rotate   \n",
              "\n",
              "                            dataset    val acc        acc  \n",
              "0  SP_the_wave_Training Aug Only120  51.558751  62.732172  \n",
              "1  SP_the_wave_Training Aug Only120  51.558751  62.732172  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw31vhpDszCq",
        "outputId": "efe12a74-bcf4-409b-cea5-c1534a586cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(shear_range=(random.randrange(0,100,10)))\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['Shear','Shear']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "Results4=Results4.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results4)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.376629</td>\n",
              "      <td>0.189516</td>\n",
              "      <td>0.670690</td>\n",
              "      <td>0.372725</td>\n",
              "      <td>0.478510</td>\n",
              "      <td>0.247882</td>\n",
              "      <td>74.547634</td>\n",
              "      <td>37.716945</td>\n",
              "      <td>55.62746</td>\n",
              "      <td>40.289522</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>98.321342</td>\n",
              "      <td>83.942479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.510533</td>\n",
              "      <td>0.040728</td>\n",
              "      <td>0.306452</td>\n",
              "      <td>0.364673</td>\n",
              "      <td>0.278839</td>\n",
              "      <td>0.231340</td>\n",
              "      <td>74.547634</td>\n",
              "      <td>37.716945</td>\n",
              "      <td>55.62746</td>\n",
              "      <td>40.289522</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>98.321342</td>\n",
              "      <td>83.942479</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.376629       0.189516  0.670690    0.372725  0.478510      0.247882   \n",
              "1   0.510533       0.040728  0.306452    0.364673  0.278839      0.231340   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var    aug  \\\n",
              "0  74.547634     37.716945      55.62746         40.289522  Shear   \n",
              "1  74.547634     37.716945      55.62746         40.289522  Shear   \n",
              "\n",
              "                            dataset    val acc        acc  \n",
              "0  SP_the_wave_Training Aug Only120  98.321342  83.942479  \n",
              "1  SP_the_wave_Training Aug Only120  98.321342  83.942479  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuYFhFbdszC_",
        "outputId": "914de2b4-c71f-4746-febf-d3b75414a863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(width_shift_range=(random.uniform(0.1,0.9)))\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['Width','Width']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "Results5=Results5.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results5)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.318926</td>\n",
              "      <td>0.207070</td>\n",
              "      <td>0.598276</td>\n",
              "      <td>0.485019</td>\n",
              "      <td>0.393841</td>\n",
              "      <td>0.314974</td>\n",
              "      <td>66.123428</td>\n",
              "      <td>42.199898</td>\n",
              "      <td>55.565499</td>\n",
              "      <td>28.186086</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>100.0</td>\n",
              "      <td>99.281007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.324621</td>\n",
              "      <td>0.267032</td>\n",
              "      <td>0.395161</td>\n",
              "      <td>0.474424</td>\n",
              "      <td>0.277779</td>\n",
              "      <td>0.321732</td>\n",
              "      <td>66.123428</td>\n",
              "      <td>42.199898</td>\n",
              "      <td>55.565499</td>\n",
              "      <td>28.186086</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>100.0</td>\n",
              "      <td>99.281007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.318926       0.207070  0.598276    0.485019  0.393841      0.314974   \n",
              "1   0.324621       0.267032  0.395161    0.474424  0.277779      0.321732   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var    aug  \\\n",
              "0  66.123428     42.199898     55.565499         28.186086  Width   \n",
              "1  66.123428     42.199898     55.565499         28.186086  Width   \n",
              "\n",
              "                            dataset  val acc        acc  \n",
              "0  SP_the_wave_Training Aug Only120    100.0  99.281007  \n",
              "1  SP_the_wave_Training Aug Only120    100.0  99.281007  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3X0w3KxszDT",
        "outputId": "62a9e00a-1668-4c65-c08b-31a504042d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(height_shift_range=(random.uniform(0.1,0.9)))\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['height','height']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "Results6=Results6.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results6)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.199605</td>\n",
              "      <td>0.244726</td>\n",
              "      <td>0.356897</td>\n",
              "      <td>0.441581</td>\n",
              "      <td>0.254748</td>\n",
              "      <td>0.312079</td>\n",
              "      <td>34.343739</td>\n",
              "      <td>42.815478</td>\n",
              "      <td>44.364508</td>\n",
              "      <td>29.977746</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>46.043167</td>\n",
              "      <td>60.2157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.432581</td>\n",
              "      <td>0.219478</td>\n",
              "      <td>0.661290</td>\n",
              "      <td>0.426002</td>\n",
              "      <td>0.490512</td>\n",
              "      <td>0.267033</td>\n",
              "      <td>34.343739</td>\n",
              "      <td>42.815478</td>\n",
              "      <td>44.364508</td>\n",
              "      <td>29.977746</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>46.043167</td>\n",
              "      <td>60.2157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.199605       0.244726  0.356897    0.441581  0.254748      0.312079   \n",
              "1   0.432581       0.219478  0.661290    0.426002  0.490512      0.267033   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var     aug  \\\n",
              "0  34.343739     42.815478     44.364508         29.977746  height   \n",
              "1  34.343739     42.815478     44.364508         29.977746  height   \n",
              "\n",
              "                            dataset    val acc      acc  \n",
              "0  SP_the_wave_Training Aug Only120  46.043167  60.2157  \n",
              "1  SP_the_wave_Training Aug Only120  46.043167  60.2157  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX1cds19v__w"
      },
      "source": [
        "# Dataset2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsmquS5LwG4V",
        "outputId": "64679d79-f600-4c77-c6e4-3642d913a78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size=32\n",
        "steps=100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[1])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# fix random seed for reproducibility\n",
        "\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(rescale=1./255)\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['No Aug','No Aug']\n",
        "df['dataset']=[Dataset[1],Dataset[1]]\n",
        "\n",
        "\n",
        "aResults=aResults.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(aResults)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.300580</td>\n",
              "      <td>0.246181</td>\n",
              "      <td>0.527586</td>\n",
              "      <td>0.450604</td>\n",
              "      <td>0.377210</td>\n",
              "      <td>0.309019</td>\n",
              "      <td>20.070248</td>\n",
              "      <td>28.287222</td>\n",
              "      <td>19.527203</td>\n",
              "      <td>29.161824</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.324314</td>\n",
              "      <td>0.266087</td>\n",
              "      <td>0.496774</td>\n",
              "      <td>0.447260</td>\n",
              "      <td>0.378722</td>\n",
              "      <td>0.314061</td>\n",
              "      <td>20.070248</td>\n",
              "      <td>28.287222</td>\n",
              "      <td>19.527203</td>\n",
              "      <td>29.161824</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.300580       0.246181  0.527586    0.450604  0.377210      0.309019   \n",
              "1   0.324314       0.266087  0.496774    0.447260  0.378722      0.314061   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var     aug  \\\n",
              "0  20.070248     28.287222     19.527203         29.161824  No Aug   \n",
              "1  20.070248     28.287222     19.527203         29.161824  No Aug   \n",
              "\n",
              "                         dataset  \n",
              "0  SP_udnie_Training Aug Only120  \n",
              "1  SP_udnie_Training Aug Only120  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDg3KcAJwG4o",
        "outputId": "5203e5f0-f32c-46d5-df08-a59494122efd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[1])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['HorizontalFlip','HorizontalFlip']\n",
        "df['dataset']=[Dataset[1],Dataset[1]]\n",
        "aResults1=aResults1.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(aResults1)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.337169</td>\n",
              "      <td>0.190570</td>\n",
              "      <td>0.575862</td>\n",
              "      <td>0.465913</td>\n",
              "      <td>0.388708</td>\n",
              "      <td>0.304915</td>\n",
              "      <td>53.13385</td>\n",
              "      <td>41.344125</td>\n",
              "      <td>40.714286</td>\n",
              "      <td>48.424146</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.477057</td>\n",
              "      <td>0.321658</td>\n",
              "      <td>0.408065</td>\n",
              "      <td>0.464438</td>\n",
              "      <td>0.299358</td>\n",
              "      <td>0.306980</td>\n",
              "      <td>53.13385</td>\n",
              "      <td>41.344125</td>\n",
              "      <td>40.714286</td>\n",
              "      <td>48.424146</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.337169       0.190570  0.575862    0.465913  0.388708      0.304915   \n",
              "1   0.477057       0.321658  0.408065    0.464438  0.299358      0.306980   \n",
              "\n",
              "   Accuracy  Accuracy var  Val Accuracy  Val Accuracy var             aug  \\\n",
              "0  53.13385     41.344125     40.714286         48.424146  HorizontalFlip   \n",
              "1  53.13385     41.344125     40.714286         48.424146  HorizontalFlip   \n",
              "\n",
              "                         dataset  \n",
              "0  SP_udnie_Training Aug Only120  \n",
              "1  SP_udnie_Training Aug Only120  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2WNB6ZcwG45",
        "outputId": "bfa99444-3cb0-48d0-bcb7-abea9bd4ccf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[1])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(vertical_flip=True)\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['VerticalFlip','VerticalFlip']\n",
        "df['dataset']=[Dataset[1],Dataset[1]]\n",
        "aResults2=aResults2.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(aResults2)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.433785</td>\n",
              "      <td>0.224506</td>\n",
              "      <td>0.420690</td>\n",
              "      <td>0.466646</td>\n",
              "      <td>0.304315</td>\n",
              "      <td>0.286910</td>\n",
              "      <td>40.45202</td>\n",
              "      <td>48.357108</td>\n",
              "      <td>60.0</td>\n",
              "      <td>48.989795</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.445873</td>\n",
              "      <td>0.229996</td>\n",
              "      <td>0.591935</td>\n",
              "      <td>0.470448</td>\n",
              "      <td>0.419783</td>\n",
              "      <td>0.318228</td>\n",
              "      <td>40.45202</td>\n",
              "      <td>48.357108</td>\n",
              "      <td>60.0</td>\n",
              "      <td>48.989795</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.433785       0.224506  0.420690    0.466646  0.304315      0.286910   \n",
              "1   0.445873       0.229996  0.591935    0.470448  0.419783      0.318228   \n",
              "\n",
              "   Accuracy  Accuracy var  Val Accuracy  Val Accuracy var           aug  \\\n",
              "0  40.45202     48.357108          60.0         48.989795  VerticalFlip   \n",
              "1  40.45202     48.357108          60.0         48.989795  VerticalFlip   \n",
              "\n",
              "                         dataset  \n",
              "0  SP_udnie_Training Aug Only120  \n",
              "1  SP_udnie_Training Aug Only120  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBQOROmuwG5B",
        "outputId": "07a37607-cfdf-41b8-dd7e-eb4430bd92be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[1])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(rotation_range=(random.randrange(0,360,30)))\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['Rotate','Rotate']\n",
        "df['dataset']=[Dataset[1],Dataset[1]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "aResults3=aResults3.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(aResults3)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.482402</td>\n",
              "      <td>0.003102</td>\n",
              "      <td>0.875862</td>\n",
              "      <td>0.206148</td>\n",
              "      <td>0.611693</td>\n",
              "      <td>0.069252</td>\n",
              "      <td>80.33051</td>\n",
              "      <td>16.915414</td>\n",
              "      <td>0.332768</td>\n",
              "      <td>0.465531</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>5.476191</td>\n",
              "      <td>62.128419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.450817</td>\n",
              "      <td>0.340479</td>\n",
              "      <td>0.120968</td>\n",
              "      <td>0.206615</td>\n",
              "      <td>0.131501</td>\n",
              "      <td>0.199426</td>\n",
              "      <td>80.33051</td>\n",
              "      <td>16.915414</td>\n",
              "      <td>0.332768</td>\n",
              "      <td>0.465531</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>5.476191</td>\n",
              "      <td>62.128419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.482402       0.003102  0.875862    0.206148  0.611693      0.069252   \n",
              "1   0.450817       0.340479  0.120968    0.206615  0.131501      0.199426   \n",
              "\n",
              "   Accuracy  Accuracy var  Val Accuracy  Val Accuracy var     aug  \\\n",
              "0  80.33051     16.915414      0.332768          0.465531  Rotate   \n",
              "1  80.33051     16.915414      0.332768          0.465531  Rotate   \n",
              "\n",
              "                         dataset   val acc        acc  \n",
              "0  SP_udnie_Training Aug Only120  5.476191  62.128419  \n",
              "1  SP_udnie_Training Aug Only120  5.476191  62.128419  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8r8_CqrwG5K",
        "outputId": "8bd76b97-2387-4183-e956-9904329dc50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[1])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(shear_range=(random.randrange(0,100,10)))\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['Shear','Shear']\n",
        "df['dataset']=[Dataset[1],Dataset[1]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "aResults4=aResults4.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(aResults4)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.357847</td>\n",
              "      <td>0.181814</td>\n",
              "      <td>0.52069</td>\n",
              "      <td>0.408464</td>\n",
              "      <td>0.397234</td>\n",
              "      <td>0.245593</td>\n",
              "      <td>57.015429</td>\n",
              "      <td>42.608877</td>\n",
              "      <td>44.135844</td>\n",
              "      <td>45.85291</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.145066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.393014</td>\n",
              "      <td>0.197480</td>\n",
              "      <td>0.43871</td>\n",
              "      <td>0.392854</td>\n",
              "      <td>0.348590</td>\n",
              "      <td>0.286724</td>\n",
              "      <td>57.015429</td>\n",
              "      <td>42.608877</td>\n",
              "      <td>44.135844</td>\n",
              "      <td>45.85291</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.145066</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var   recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.357847       0.181814  0.52069    0.408464  0.397234      0.245593   \n",
              "1   0.393014       0.197480  0.43871    0.392854  0.348590      0.286724   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var    aug  \\\n",
              "0  57.015429     42.608877     44.135844          45.85291  Shear   \n",
              "1  57.015429     42.608877     44.135844          45.85291  Shear   \n",
              "\n",
              "                         dataset  val acc       acc  \n",
              "0  SP_udnie_Training Aug Only120    100.0  8.145066  \n",
              "1  SP_udnie_Training Aug Only120    100.0  8.145066  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU_tYpDdwG5V",
        "outputId": "e2cebb51-94de-4ebb-9c45-39f7342670d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[1])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(width_shift_range=(random.uniform(0.1,0.9)))\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['Width','Width']\n",
        "df['dataset']=[Dataset[1],Dataset[1]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "aResults5=aResults5.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(aResults5)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.492365</td>\n",
              "      <td>0.033932</td>\n",
              "      <td>0.732759</td>\n",
              "      <td>0.299375</td>\n",
              "      <td>0.558675</td>\n",
              "      <td>0.112525</td>\n",
              "      <td>80.973756</td>\n",
              "      <td>18.018571</td>\n",
              "      <td>15.571429</td>\n",
              "      <td>31.142857</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>71.904761</td>\n",
              "      <td>56.956005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.599796</td>\n",
              "      <td>0.134300</td>\n",
              "      <td>0.282258</td>\n",
              "      <td>0.303594</td>\n",
              "      <td>0.273518</td>\n",
              "      <td>0.250371</td>\n",
              "      <td>80.973756</td>\n",
              "      <td>18.018571</td>\n",
              "      <td>15.571429</td>\n",
              "      <td>31.142857</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>71.904761</td>\n",
              "      <td>56.956005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.492365       0.033932  0.732759    0.299375  0.558675      0.112525   \n",
              "1   0.599796       0.134300  0.282258    0.303594  0.273518      0.250371   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var    aug  \\\n",
              "0  80.973756     18.018571     15.571429         31.142857  Width   \n",
              "1  80.973756     18.018571     15.571429         31.142857  Width   \n",
              "\n",
              "                         dataset    val acc        acc  \n",
              "0  SP_udnie_Training Aug Only120  71.904761  56.956005  \n",
              "1  SP_udnie_Training Aug Only120  71.904761  56.956005  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdiORQfCwG5f",
        "outputId": "4b3ab3be-59ec-43e8-8895-5844744b0d4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[1])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(height_shift_range=(random.uniform(0.1,0.9)))\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['height','height']\n",
        "df['dataset']=[Dataset[1],Dataset[1]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "aResults6=aResults6.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(aResults6)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.289035</td>\n",
              "      <td>0.236028</td>\n",
              "      <td>0.424138</td>\n",
              "      <td>0.456731</td>\n",
              "      <td>0.308125</td>\n",
              "      <td>0.291822</td>\n",
              "      <td>44.969425</td>\n",
              "      <td>43.660074</td>\n",
              "      <td>80.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.59453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.426333</td>\n",
              "      <td>0.214752</td>\n",
              "      <td>0.577419</td>\n",
              "      <td>0.453011</td>\n",
              "      <td>0.420276</td>\n",
              "      <td>0.303339</td>\n",
              "      <td>44.969425</td>\n",
              "      <td>43.660074</td>\n",
              "      <td>80.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.59453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.289035       0.236028  0.424138    0.456731  0.308125      0.291822   \n",
              "1   0.426333       0.214752  0.577419    0.453011  0.420276      0.303339   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var     aug  \\\n",
              "0  44.969425     43.660074          80.0              40.0  height   \n",
              "1  44.969425     43.660074          80.0              40.0  height   \n",
              "\n",
              "                         dataset  val acc      acc  \n",
              "0  SP_udnie_Training Aug Only120    100.0  0.59453  \n",
              "1  SP_udnie_Training Aug Only120    100.0  0.59453  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmZr1SEdOUxs"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mvmX_cKKmaC",
        "outputId": "0e4091d6-fc30-4815-8a95-2a08f3f49c1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Final=pd.DataFrame([])\n",
        "Final=Final.append(Results)\n",
        "Final=Final.append(Results1)\n",
        "Final=Final.append(Results2)\n",
        "Final=Final.append(Results3)\n",
        "Final=Final.append(Results4)\n",
        "Final=Final.append(Results5)\n",
        "Final=Final.append(Results6)\n",
        "\n",
        "Final=Final.append(aResults)\n",
        "Final=Final.append(aResults1)\n",
        "Final=Final.append(aResults2)\n",
        "Final=Final.append(aResults3)\n",
        "Final=Final.append(aResults4)\n",
        "Final=Final.append(aResults5)\n",
        "Final=Final.append(aResults6)\n",
        "\n",
        "Final=Final.append(bResults)\n",
        "Final=Final.append(bResults1)\n",
        "Final=Final.append(bResults2)\n",
        "Final=Final.append(bResults3)\n",
        "Final=Final.append(bResults4)\n",
        "Final=Final.append(bResults5)\n",
        "Final=Final.append(bResults6)\n",
        "\n",
        "Final=Final.append(cResults)\n",
        "Final=Final.append(cResults1)\n",
        "Final=Final.append(cResults2)\n",
        "Final=Final.append(cResults3)\n",
        "Final=Final.append(cResults4)\n",
        "Final=Final.append(cResults5)\n",
        "Final=Final.append(cResults6)\n",
        "\n",
        "Final=Final.append(dResults)\n",
        "Final=Final.append(dResults1)\n",
        "Final=Final.append(dResults2)\n",
        "Final=Final.append(dResults3)\n",
        "Final=Final.append(dResults4)\n",
        "Final=Final.append(dResults5)\n",
        "Final=Final.append(dResults6)\n",
        "\n",
        "Final=Final.append(eResults)\n",
        "Final=Final.append(eResults1)\n",
        "Final=Final.append(eResults2)\n",
        "Final=Final.append(eResults3)\n",
        "Final=Final.append(eResults4)\n",
        "Final=Final.append(eResults5)\n",
        "Final=Final.append(eResults6)\n",
        "\n",
        "Final=Final.append(fResults)\n",
        "Final=Final.append(fResults1)\n",
        "Final=Final.append(fResults2)\n",
        "Final=Final.append(fResults3)\n",
        "Final=Final.append(fResults4)\n",
        "Final=Final.append(fResults5)\n",
        "Final=Final.append(fResults6)\n",
        "\n",
        "Final=Final.append(gResults)\n",
        "Final=Final.append(gResults1)\n",
        "Final=Final.append(gResults2)\n",
        "Final=Final.append(gResults3)\n",
        "Final=Final.append(gResults4)\n",
        "Final=Final.append(gResults5)\n",
        "Final=Final.append(gResults6)\n",
        "\n",
        "\n",
        "Final=Final.append(hResults)\n",
        "Final=Final.append(hResults1)\n",
        "Final=Final.append(hResults2)\n",
        "Final=Final.append(hResults3)\n",
        "Final=Final.append(hResults4)\n",
        "Final=Final.append(hResults5)\n",
        "Final=Final.append(hResults6)\n",
        "\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.397255</td>\n",
              "      <td>0.199076</td>\n",
              "      <td>0.584483</td>\n",
              "      <td>0.474761</td>\n",
              "      <td>0.396564</td>\n",
              "      <td>0.316944</td>\n",
              "      <td>49.670519</td>\n",
              "      <td>44.610582</td>\n",
              "      <td>49.975790</td>\n",
              "      <td>44.403143</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.351139</td>\n",
              "      <td>0.296360</td>\n",
              "      <td>0.440323</td>\n",
              "      <td>0.460104</td>\n",
              "      <td>0.337175</td>\n",
              "      <td>0.304363</td>\n",
              "      <td>49.670519</td>\n",
              "      <td>44.610582</td>\n",
              "      <td>49.975790</td>\n",
              "      <td>44.403143</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.189624</td>\n",
              "      <td>0.232316</td>\n",
              "      <td>0.370690</td>\n",
              "      <td>0.456359</td>\n",
              "      <td>0.250702</td>\n",
              "      <td>0.307450</td>\n",
              "      <td>38.093525</td>\n",
              "      <td>46.752129</td>\n",
              "      <td>49.352977</td>\n",
              "      <td>42.306231</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.384074</td>\n",
              "      <td>0.200221</td>\n",
              "      <td>0.616129</td>\n",
              "      <td>0.470835</td>\n",
              "      <td>0.435281</td>\n",
              "      <td>0.304230</td>\n",
              "      <td>38.093525</td>\n",
              "      <td>46.752129</td>\n",
              "      <td>49.352977</td>\n",
              "      <td>42.306231</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.405741</td>\n",
              "      <td>0.205036</td>\n",
              "      <td>0.674138</td>\n",
              "      <td>0.351166</td>\n",
              "      <td>0.502826</td>\n",
              "      <td>0.252540</td>\n",
              "      <td>62.347742</td>\n",
              "      <td>37.355355</td>\n",
              "      <td>49.089646</td>\n",
              "      <td>28.641294</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.446449</td>\n",
              "      <td>0.242040</td>\n",
              "      <td>0.375806</td>\n",
              "      <td>0.349803</td>\n",
              "      <td>0.361692</td>\n",
              "      <td>0.244029</td>\n",
              "      <td>62.347742</td>\n",
              "      <td>37.355355</td>\n",
              "      <td>49.089646</td>\n",
              "      <td>28.641294</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.437613</td>\n",
              "      <td>0.051906</td>\n",
              "      <td>0.431034</td>\n",
              "      <td>0.235457</td>\n",
              "      <td>0.398664</td>\n",
              "      <td>0.191575</td>\n",
              "      <td>59.662192</td>\n",
              "      <td>26.636895</td>\n",
              "      <td>63.846912</td>\n",
              "      <td>18.704849</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>51.558751</td>\n",
              "      <td>62.732172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.498888</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.525806</td>\n",
              "      <td>0.223456</td>\n",
              "      <td>0.492386</td>\n",
              "      <td>0.090576</td>\n",
              "      <td>59.662192</td>\n",
              "      <td>26.636895</td>\n",
              "      <td>63.846912</td>\n",
              "      <td>18.704849</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>51.558751</td>\n",
              "      <td>62.732172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.376629</td>\n",
              "      <td>0.189516</td>\n",
              "      <td>0.670690</td>\n",
              "      <td>0.372725</td>\n",
              "      <td>0.478510</td>\n",
              "      <td>0.247882</td>\n",
              "      <td>74.547634</td>\n",
              "      <td>37.716945</td>\n",
              "      <td>55.627460</td>\n",
              "      <td>40.289522</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>98.321342</td>\n",
              "      <td>83.942479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.510533</td>\n",
              "      <td>0.040728</td>\n",
              "      <td>0.306452</td>\n",
              "      <td>0.364673</td>\n",
              "      <td>0.278839</td>\n",
              "      <td>0.231340</td>\n",
              "      <td>74.547634</td>\n",
              "      <td>37.716945</td>\n",
              "      <td>55.627460</td>\n",
              "      <td>40.289522</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>98.321342</td>\n",
              "      <td>83.942479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.318926</td>\n",
              "      <td>0.207070</td>\n",
              "      <td>0.598276</td>\n",
              "      <td>0.485019</td>\n",
              "      <td>0.393841</td>\n",
              "      <td>0.314974</td>\n",
              "      <td>66.123428</td>\n",
              "      <td>42.199898</td>\n",
              "      <td>55.565499</td>\n",
              "      <td>28.186086</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.281007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.324621</td>\n",
              "      <td>0.267032</td>\n",
              "      <td>0.395161</td>\n",
              "      <td>0.474424</td>\n",
              "      <td>0.277779</td>\n",
              "      <td>0.321732</td>\n",
              "      <td>66.123428</td>\n",
              "      <td>42.199898</td>\n",
              "      <td>55.565499</td>\n",
              "      <td>28.186086</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.281007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.199605</td>\n",
              "      <td>0.244726</td>\n",
              "      <td>0.356897</td>\n",
              "      <td>0.441581</td>\n",
              "      <td>0.254748</td>\n",
              "      <td>0.312079</td>\n",
              "      <td>34.343739</td>\n",
              "      <td>42.815478</td>\n",
              "      <td>44.364508</td>\n",
              "      <td>29.977746</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>46.043167</td>\n",
              "      <td>60.215700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.432581</td>\n",
              "      <td>0.219478</td>\n",
              "      <td>0.661290</td>\n",
              "      <td>0.426002</td>\n",
              "      <td>0.490512</td>\n",
              "      <td>0.267033</td>\n",
              "      <td>34.343739</td>\n",
              "      <td>42.815478</td>\n",
              "      <td>44.364508</td>\n",
              "      <td>29.977746</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_the_wave_Training Aug Only120</td>\n",
              "      <td>46.043167</td>\n",
              "      <td>60.215700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.300580</td>\n",
              "      <td>0.246181</td>\n",
              "      <td>0.527586</td>\n",
              "      <td>0.450604</td>\n",
              "      <td>0.377210</td>\n",
              "      <td>0.309019</td>\n",
              "      <td>20.070248</td>\n",
              "      <td>28.287222</td>\n",
              "      <td>19.527203</td>\n",
              "      <td>29.161824</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.324314</td>\n",
              "      <td>0.266087</td>\n",
              "      <td>0.496774</td>\n",
              "      <td>0.447260</td>\n",
              "      <td>0.378722</td>\n",
              "      <td>0.314061</td>\n",
              "      <td>20.070248</td>\n",
              "      <td>28.287222</td>\n",
              "      <td>19.527203</td>\n",
              "      <td>29.161824</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.337169</td>\n",
              "      <td>0.190570</td>\n",
              "      <td>0.575862</td>\n",
              "      <td>0.465913</td>\n",
              "      <td>0.388708</td>\n",
              "      <td>0.304915</td>\n",
              "      <td>53.133850</td>\n",
              "      <td>41.344125</td>\n",
              "      <td>40.714286</td>\n",
              "      <td>48.424146</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.477057</td>\n",
              "      <td>0.321658</td>\n",
              "      <td>0.408065</td>\n",
              "      <td>0.464438</td>\n",
              "      <td>0.299358</td>\n",
              "      <td>0.306980</td>\n",
              "      <td>53.133850</td>\n",
              "      <td>41.344125</td>\n",
              "      <td>40.714286</td>\n",
              "      <td>48.424146</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.433785</td>\n",
              "      <td>0.224506</td>\n",
              "      <td>0.420690</td>\n",
              "      <td>0.466646</td>\n",
              "      <td>0.304315</td>\n",
              "      <td>0.286910</td>\n",
              "      <td>40.452020</td>\n",
              "      <td>48.357108</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>48.989795</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.445873</td>\n",
              "      <td>0.229996</td>\n",
              "      <td>0.591935</td>\n",
              "      <td>0.470448</td>\n",
              "      <td>0.419783</td>\n",
              "      <td>0.318228</td>\n",
              "      <td>40.452020</td>\n",
              "      <td>48.357108</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>48.989795</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.482402</td>\n",
              "      <td>0.003102</td>\n",
              "      <td>0.875862</td>\n",
              "      <td>0.206148</td>\n",
              "      <td>0.611693</td>\n",
              "      <td>0.069252</td>\n",
              "      <td>80.330510</td>\n",
              "      <td>16.915414</td>\n",
              "      <td>0.332768</td>\n",
              "      <td>0.465531</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>5.476191</td>\n",
              "      <td>62.128419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.450817</td>\n",
              "      <td>0.340479</td>\n",
              "      <td>0.120968</td>\n",
              "      <td>0.206615</td>\n",
              "      <td>0.131501</td>\n",
              "      <td>0.199426</td>\n",
              "      <td>80.330510</td>\n",
              "      <td>16.915414</td>\n",
              "      <td>0.332768</td>\n",
              "      <td>0.465531</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>5.476191</td>\n",
              "      <td>62.128419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.357847</td>\n",
              "      <td>0.181814</td>\n",
              "      <td>0.520690</td>\n",
              "      <td>0.408464</td>\n",
              "      <td>0.397234</td>\n",
              "      <td>0.245593</td>\n",
              "      <td>57.015429</td>\n",
              "      <td>42.608877</td>\n",
              "      <td>44.135844</td>\n",
              "      <td>45.852910</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>8.145066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.393014</td>\n",
              "      <td>0.197480</td>\n",
              "      <td>0.438710</td>\n",
              "      <td>0.392854</td>\n",
              "      <td>0.348590</td>\n",
              "      <td>0.286724</td>\n",
              "      <td>57.015429</td>\n",
              "      <td>42.608877</td>\n",
              "      <td>44.135844</td>\n",
              "      <td>45.852910</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>8.145066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.492365</td>\n",
              "      <td>0.033932</td>\n",
              "      <td>0.732759</td>\n",
              "      <td>0.299375</td>\n",
              "      <td>0.558675</td>\n",
              "      <td>0.112525</td>\n",
              "      <td>80.973756</td>\n",
              "      <td>18.018571</td>\n",
              "      <td>15.571429</td>\n",
              "      <td>31.142857</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>71.904761</td>\n",
              "      <td>56.956005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.599796</td>\n",
              "      <td>0.134300</td>\n",
              "      <td>0.282258</td>\n",
              "      <td>0.303594</td>\n",
              "      <td>0.273518</td>\n",
              "      <td>0.250371</td>\n",
              "      <td>80.973756</td>\n",
              "      <td>18.018571</td>\n",
              "      <td>15.571429</td>\n",
              "      <td>31.142857</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>71.904761</td>\n",
              "      <td>56.956005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.289035</td>\n",
              "      <td>0.236028</td>\n",
              "      <td>0.424138</td>\n",
              "      <td>0.456731</td>\n",
              "      <td>0.308125</td>\n",
              "      <td>0.291822</td>\n",
              "      <td>44.969425</td>\n",
              "      <td>43.660074</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.594530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.426333</td>\n",
              "      <td>0.214752</td>\n",
              "      <td>0.577419</td>\n",
              "      <td>0.453011</td>\n",
              "      <td>0.420276</td>\n",
              "      <td>0.303339</td>\n",
              "      <td>44.969425</td>\n",
              "      <td>43.660074</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_udnie_Training Aug Only120</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>0.594530</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.397255       0.199076  0.584483    0.474761  0.396564      0.316944   \n",
              "1   0.351139       0.296360  0.440323    0.460104  0.337175      0.304363   \n",
              "0   0.189624       0.232316  0.370690    0.456359  0.250702      0.307450   \n",
              "1   0.384074       0.200221  0.616129    0.470835  0.435281      0.304230   \n",
              "0   0.405741       0.205036  0.674138    0.351166  0.502826      0.252540   \n",
              "1   0.446449       0.242040  0.375806    0.349803  0.361692      0.244029   \n",
              "0   0.437613       0.051906  0.431034    0.235457  0.398664      0.191575   \n",
              "1   0.498888       0.036000  0.525806    0.223456  0.492386      0.090576   \n",
              "0   0.376629       0.189516  0.670690    0.372725  0.478510      0.247882   \n",
              "1   0.510533       0.040728  0.306452    0.364673  0.278839      0.231340   \n",
              "0   0.318926       0.207070  0.598276    0.485019  0.393841      0.314974   \n",
              "1   0.324621       0.267032  0.395161    0.474424  0.277779      0.321732   \n",
              "0   0.199605       0.244726  0.356897    0.441581  0.254748      0.312079   \n",
              "1   0.432581       0.219478  0.661290    0.426002  0.490512      0.267033   \n",
              "0   0.300580       0.246181  0.527586    0.450604  0.377210      0.309019   \n",
              "1   0.324314       0.266087  0.496774    0.447260  0.378722      0.314061   \n",
              "0   0.337169       0.190570  0.575862    0.465913  0.388708      0.304915   \n",
              "1   0.477057       0.321658  0.408065    0.464438  0.299358      0.306980   \n",
              "0   0.433785       0.224506  0.420690    0.466646  0.304315      0.286910   \n",
              "1   0.445873       0.229996  0.591935    0.470448  0.419783      0.318228   \n",
              "0   0.482402       0.003102  0.875862    0.206148  0.611693      0.069252   \n",
              "1   0.450817       0.340479  0.120968    0.206615  0.131501      0.199426   \n",
              "0   0.357847       0.181814  0.520690    0.408464  0.397234      0.245593   \n",
              "1   0.393014       0.197480  0.438710    0.392854  0.348590      0.286724   \n",
              "0   0.492365       0.033932  0.732759    0.299375  0.558675      0.112525   \n",
              "1   0.599796       0.134300  0.282258    0.303594  0.273518      0.250371   \n",
              "0   0.289035       0.236028  0.424138    0.456731  0.308125      0.291822   \n",
              "1   0.426333       0.214752  0.577419    0.453011  0.420276      0.303339   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var             aug  \\\n",
              "0  49.670519     44.610582     49.975790         44.403143          No Aug   \n",
              "1  49.670519     44.610582     49.975790         44.403143          No Aug   \n",
              "0  38.093525     46.752129     49.352977         42.306231  HorizontalFlip   \n",
              "1  38.093525     46.752129     49.352977         42.306231  HorizontalFlip   \n",
              "0  62.347742     37.355355     49.089646         28.641294    VerticalFlip   \n",
              "1  62.347742     37.355355     49.089646         28.641294    VerticalFlip   \n",
              "0  59.662192     26.636895     63.846912         18.704849          Rotate   \n",
              "1  59.662192     26.636895     63.846912         18.704849          Rotate   \n",
              "0  74.547634     37.716945     55.627460         40.289522           Shear   \n",
              "1  74.547634     37.716945     55.627460         40.289522           Shear   \n",
              "0  66.123428     42.199898     55.565499         28.186086           Width   \n",
              "1  66.123428     42.199898     55.565499         28.186086           Width   \n",
              "0  34.343739     42.815478     44.364508         29.977746          height   \n",
              "1  34.343739     42.815478     44.364508         29.977746          height   \n",
              "0  20.070248     28.287222     19.527203         29.161824          No Aug   \n",
              "1  20.070248     28.287222     19.527203         29.161824          No Aug   \n",
              "0  53.133850     41.344125     40.714286         48.424146  HorizontalFlip   \n",
              "1  53.133850     41.344125     40.714286         48.424146  HorizontalFlip   \n",
              "0  40.452020     48.357108     60.000000         48.989795    VerticalFlip   \n",
              "1  40.452020     48.357108     60.000000         48.989795    VerticalFlip   \n",
              "0  80.330510     16.915414      0.332768          0.465531          Rotate   \n",
              "1  80.330510     16.915414      0.332768          0.465531          Rotate   \n",
              "0  57.015429     42.608877     44.135844         45.852910           Shear   \n",
              "1  57.015429     42.608877     44.135844         45.852910           Shear   \n",
              "0  80.973756     18.018571     15.571429         31.142857           Width   \n",
              "1  80.973756     18.018571     15.571429         31.142857           Width   \n",
              "0  44.969425     43.660074     80.000000         40.000000          height   \n",
              "1  44.969425     43.660074     80.000000         40.000000          height   \n",
              "\n",
              "                            dataset     val acc        acc  \n",
              "0  SP_the_wave_Training Aug Only120         NaN        NaN  \n",
              "1  SP_the_wave_Training Aug Only120         NaN        NaN  \n",
              "0  SP_the_wave_Training Aug Only120         NaN        NaN  \n",
              "1  SP_the_wave_Training Aug Only120         NaN        NaN  \n",
              "0  SP_the_wave_Training Aug Only120         NaN        NaN  \n",
              "1  SP_the_wave_Training Aug Only120         NaN        NaN  \n",
              "0  SP_the_wave_Training Aug Only120   51.558751  62.732172  \n",
              "1  SP_the_wave_Training Aug Only120   51.558751  62.732172  \n",
              "0  SP_the_wave_Training Aug Only120   98.321342  83.942479  \n",
              "1  SP_the_wave_Training Aug Only120   98.321342  83.942479  \n",
              "0  SP_the_wave_Training Aug Only120  100.000000  99.281007  \n",
              "1  SP_the_wave_Training Aug Only120  100.000000  99.281007  \n",
              "0  SP_the_wave_Training Aug Only120   46.043167  60.215700  \n",
              "1  SP_the_wave_Training Aug Only120   46.043167  60.215700  \n",
              "0     SP_udnie_Training Aug Only120         NaN        NaN  \n",
              "1     SP_udnie_Training Aug Only120         NaN        NaN  \n",
              "0     SP_udnie_Training Aug Only120         NaN        NaN  \n",
              "1     SP_udnie_Training Aug Only120         NaN        NaN  \n",
              "0     SP_udnie_Training Aug Only120         NaN        NaN  \n",
              "1     SP_udnie_Training Aug Only120         NaN        NaN  \n",
              "0     SP_udnie_Training Aug Only120    5.476191  62.128419  \n",
              "1     SP_udnie_Training Aug Only120    5.476191  62.128419  \n",
              "0     SP_udnie_Training Aug Only120  100.000000   8.145066  \n",
              "1     SP_udnie_Training Aug Only120  100.000000   8.145066  \n",
              "0     SP_udnie_Training Aug Only120   71.904761  56.956005  \n",
              "1     SP_udnie_Training Aug Only120   71.904761  56.956005  \n",
              "0     SP_udnie_Training Aug Only120  100.000000   0.594530  \n",
              "1     SP_udnie_Training Aug Only120  100.000000   0.594530  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}