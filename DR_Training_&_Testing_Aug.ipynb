{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DR Training & Testing Aug.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMIwWkh2Lj65xkzrA12Vcit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikarRajcomar-Engineer/Ensemble/blob/master/DR_Training_%26_Testing_Aug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iPBPO9MN6qH",
        "outputId": "15e49ee9-2a93-4a8d-d652-28ee33d345f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtsQ-d8SvoIu"
      },
      "source": [
        "# Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teM_sn5eZ3vs"
      },
      "source": [
        "import pandas as pd\n",
        "%tensorflow_version 2.x\n",
        "path='/content/drive/My Drive/B3 MSC DR Dataset/'      \n",
        "Results=pd.DataFrame([])\n",
        "Results1=pd.DataFrame([])\n",
        "Results2=pd.DataFrame([])\n",
        "Results3=pd.DataFrame([])\n",
        "Results4=pd.DataFrame([])\n",
        "Results5=pd.DataFrame([])\n",
        "Results6=pd.DataFrame([])\n",
        "\n",
        "aResults=pd.DataFrame([])\n",
        "aResults1=pd.DataFrame([])\n",
        "aResults2=pd.DataFrame([])\n",
        "aResults3=pd.DataFrame([])\n",
        "aResults4=pd.DataFrame([])\n",
        "aResults5=pd.DataFrame([])\n",
        "aResults6=pd.DataFrame([])\n",
        "\n",
        "bResults=pd.DataFrame([])\n",
        "bResults1=pd.DataFrame([])\n",
        "bResults2=pd.DataFrame([])\n",
        "bResults3=pd.DataFrame([])\n",
        "bResults4=pd.DataFrame([])\n",
        "bResults5=pd.DataFrame([])\n",
        "bResults6=pd.DataFrame([])\n",
        "\n",
        "cResults=pd.DataFrame([])\n",
        "cResults1=pd.DataFrame([])\n",
        "cResults2=pd.DataFrame([])\n",
        "cResults3=pd.DataFrame([])\n",
        "cResults4=pd.DataFrame([])\n",
        "cResults5=pd.DataFrame([])\n",
        "cResults6=pd.DataFrame([])\n",
        "\n",
        "dResults=pd.DataFrame([])\n",
        "dResults1=pd.DataFrame([])\n",
        "dResults2=pd.DataFrame([])\n",
        "dResults3=pd.DataFrame([])\n",
        "dResults4=pd.DataFrame([])\n",
        "dResults5=pd.DataFrame([])\n",
        "dResults6=pd.DataFrame([])\n",
        "\n",
        "eResults=pd.DataFrame([])\n",
        "eResults1=pd.DataFrame([])\n",
        "eResults2=pd.DataFrame([])\n",
        "eResults3=pd.DataFrame([])\n",
        "eResults4=pd.DataFrame([])\n",
        "eResults5=pd.DataFrame([])\n",
        "eResults6=pd.DataFrame([])\n",
        "\n",
        "fResults=pd.DataFrame([])\n",
        "fResults1=pd.DataFrame([])\n",
        "fResults2=pd.DataFrame([])\n",
        "fResults3=pd.DataFrame([])\n",
        "fResults4=pd.DataFrame([])\n",
        "fResults5=pd.DataFrame([])\n",
        "fResults6=pd.DataFrame([])\n",
        "\n",
        "gResults=pd.DataFrame([])\n",
        "gResults1=pd.DataFrame([])\n",
        "gResults2=pd.DataFrame([])\n",
        "gResults3=pd.DataFrame([])\n",
        "gResults4=pd.DataFrame([])\n",
        "gResults5=pd.DataFrame([])\n",
        "gResults6=pd.DataFrame([])\n",
        "\n",
        "hResults=pd.DataFrame([])\n",
        "hResults1=pd.DataFrame([])\n",
        "hResults2=pd.DataFrame([])\n",
        "hResults3=pd.DataFrame([])\n",
        "hResults4=pd.DataFrame([])\n",
        "hResults5=pd.DataFrame([])\n",
        "hResults6=pd.DataFrame([])\n",
        "\n",
        "\n",
        "Dataset=['SP_the_wave120']\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtxIqFgrOCO1"
      },
      "source": [
        "# Dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoQeLdNkszBc",
        "outputId": "ea9712ff-6847-4ec8-c647-ce049fc0d70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "\n",
        "\n",
        "\n",
        "batch_size=192\n",
        "steps=100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# fix random seed for reproducibility\n",
        "\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "            \n",
        "      datagen = ImageDataGenerator(rescale=1./255)\n",
        "      val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['No Aug','No Aug']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "\n",
        "\n",
        "Results=Results.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.279470</td>\n",
              "      <td>0.228186</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.489898</td>\n",
              "      <td>0.381325</td>\n",
              "      <td>0.311351</td>\n",
              "      <td>60.023938</td>\n",
              "      <td>48.960492</td>\n",
              "      <td>59.952153</td>\n",
              "      <td>48.950806</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.213687</td>\n",
              "      <td>0.261711</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.489898</td>\n",
              "      <td>0.278561</td>\n",
              "      <td>0.341166</td>\n",
              "      <td>60.023938</td>\n",
              "      <td>48.960492</td>\n",
              "      <td>59.952153</td>\n",
              "      <td>48.950806</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var  recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.279470       0.228186     0.6    0.489898  0.381325      0.311351   \n",
              "1   0.213687       0.261711     0.4    0.489898  0.278561      0.341166   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var     aug  \\\n",
              "0  60.023938     48.960492     59.952153         48.950806  No Aug   \n",
              "1  60.023938     48.960492     59.952153         48.950806  No Aug   \n",
              "\n",
              "          dataset  \n",
              "0  SP_the_wave120  \n",
              "1  SP_the_wave120  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXwiJXlgszB2",
        "outputId": "5eff92e1-cd36-426c-e2fc-2f5670a8ab2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "      val_datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['HorizontalFlip','HorizontalFlip']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "Results1=Results1.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results1)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.459532</td>\n",
              "      <td>0.037440</td>\n",
              "      <td>0.636967</td>\n",
              "      <td>0.293680</td>\n",
              "      <td>0.504206</td>\n",
              "      <td>0.119854</td>\n",
              "      <td>66.91701</td>\n",
              "      <td>25.703386</td>\n",
              "      <td>68.348077</td>\n",
              "      <td>23.308606</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.478677</td>\n",
              "      <td>0.076398</td>\n",
              "      <td>0.349587</td>\n",
              "      <td>0.294166</td>\n",
              "      <td>0.339408</td>\n",
              "      <td>0.247404</td>\n",
              "      <td>66.91701</td>\n",
              "      <td>25.703386</td>\n",
              "      <td>68.348077</td>\n",
              "      <td>23.308606</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.459532       0.037440  0.636967    0.293680  0.504206      0.119854   \n",
              "1   0.478677       0.076398  0.349587    0.294166  0.339408      0.247404   \n",
              "\n",
              "   Accuracy  Accuracy var  Val Accuracy  Val Accuracy var             aug  \\\n",
              "0  66.91701     25.703386     68.348077         23.308606  HorizontalFlip   \n",
              "1  66.91701     25.703386     68.348077         23.308606  HorizontalFlip   \n",
              "\n",
              "          dataset  \n",
              "0  SP_the_wave120  \n",
              "1  SP_the_wave120  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AncgPCnLszCG",
        "outputId": "44dc1802-02ba-43e8-c822-d9e3bf0c6ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(vertical_flip=True)\n",
        "      val_datagen = ImageDataGenerator(vertical_flip=True)\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['VerticalFlip','VerticalFlip']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "Results2=Results2.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results2)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.275028</td>\n",
              "      <td>0.224724</td>\n",
              "      <td>0.345972</td>\n",
              "      <td>0.370857</td>\n",
              "      <td>0.286590</td>\n",
              "      <td>0.253027</td>\n",
              "      <td>36.833034</td>\n",
              "      <td>36.78913</td>\n",
              "      <td>37.053457</td>\n",
              "      <td>36.802465</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.425736</td>\n",
              "      <td>0.212898</td>\n",
              "      <td>0.649174</td>\n",
              "      <td>0.369774</td>\n",
              "      <td>0.506446</td>\n",
              "      <td>0.260354</td>\n",
              "      <td>36.833034</td>\n",
              "      <td>36.78913</td>\n",
              "      <td>37.053457</td>\n",
              "      <td>36.802465</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.275028       0.224724  0.345972    0.370857  0.286590      0.253027   \n",
              "1   0.425736       0.212898  0.649174    0.369774  0.506446      0.260354   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var           aug  \\\n",
              "0  36.833034      36.78913     37.053457         36.802465  VerticalFlip   \n",
              "1  36.833034      36.78913     37.053457         36.802465  VerticalFlip   \n",
              "\n",
              "          dataset  \n",
              "0  SP_the_wave120  \n",
              "1  SP_the_wave120  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixlQV01szCU",
        "outputId": "fcd14b38-8ffc-4895-a1bf-17a9190744aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(rotation_range=(random.randrange(0,360,30)))\n",
        "      val_datagen = ImageDataGenerator(rotation_range=(random.randrange(0,360,30)))\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['Rotate','Rotate']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "Results3=Results3.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results3)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.379242</td>\n",
              "      <td>0.190103</td>\n",
              "      <td>0.564455</td>\n",
              "      <td>0.463417</td>\n",
              "      <td>0.374018</td>\n",
              "      <td>0.303810</td>\n",
              "      <td>57.329335</td>\n",
              "      <td>44.96551</td>\n",
              "      <td>57.08134</td>\n",
              "      <td>46.729195</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>99.520385</td>\n",
              "      <td>94.254935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.642834</td>\n",
              "      <td>0.183221</td>\n",
              "      <td>0.435124</td>\n",
              "      <td>0.463158</td>\n",
              "      <td>0.335487</td>\n",
              "      <td>0.304394</td>\n",
              "      <td>57.329335</td>\n",
              "      <td>44.96551</td>\n",
              "      <td>57.08134</td>\n",
              "      <td>46.729195</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>99.520385</td>\n",
              "      <td>94.254935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.379242       0.190103  0.564455    0.463417  0.374018      0.303810   \n",
              "1   0.642834       0.183221  0.435124    0.463158  0.335487      0.304394   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var     aug  \\\n",
              "0  57.329335      44.96551      57.08134         46.729195  Rotate   \n",
              "1  57.329335      44.96551      57.08134         46.729195  Rotate   \n",
              "\n",
              "          dataset    val acc        acc  \n",
              "0  SP_the_wave120  99.520385  94.254935  \n",
              "1  SP_the_wave120  99.520385  94.254935  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw31vhpDszCq",
        "outputId": "64c277ab-2c1a-40ab-b7de-22dfbaf05b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(shear_range=(random.randrange(0,100,10)))\n",
        "      val_datagen = ImageDataGenerator(shear_range=(random.randrange(0,100,10)))\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['Shear','Shear']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "Results4=Results4.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results4)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.252676</td>\n",
              "      <td>0.210750</td>\n",
              "      <td>0.296682</td>\n",
              "      <td>0.380216</td>\n",
              "      <td>0.239557</td>\n",
              "      <td>0.251700</td>\n",
              "      <td>29.073909</td>\n",
              "      <td>37.186501</td>\n",
              "      <td>31.503677</td>\n",
              "      <td>37.628919</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>44.604316</td>\n",
              "      <td>37.462598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.555884</td>\n",
              "      <td>0.055712</td>\n",
              "      <td>0.688430</td>\n",
              "      <td>0.374863</td>\n",
              "      <td>0.519799</td>\n",
              "      <td>0.261168</td>\n",
              "      <td>29.073909</td>\n",
              "      <td>37.186501</td>\n",
              "      <td>31.503677</td>\n",
              "      <td>37.628919</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>44.604316</td>\n",
              "      <td>37.462598</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.252676       0.210750  0.296682    0.380216  0.239557      0.251700   \n",
              "1   0.555884       0.055712  0.688430    0.374863  0.519799      0.261168   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var    aug  \\\n",
              "0  29.073909     37.186501     31.503677         37.628919  Shear   \n",
              "1  29.073909     37.186501     31.503677         37.628919  Shear   \n",
              "\n",
              "          dataset    val acc        acc  \n",
              "0  SP_the_wave120  44.604316  37.462598  \n",
              "1  SP_the_wave120  44.604316  37.462598  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuYFhFbdszC_",
        "outputId": "a4ce7521-7124-4c7d-b819-b3f4d5d82973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(width_shift_range=(random.uniform(0.1,0.9)))\n",
        "      val_datagen = ImageDataGenerator(width_shift_range=(random.uniform(0.1,0.9)))\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['Width','Width']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "Results5=Results5.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results5)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.272266</td>\n",
              "      <td>0.222710</td>\n",
              "      <td>0.433175</td>\n",
              "      <td>0.385315</td>\n",
              "      <td>0.329507</td>\n",
              "      <td>0.273314</td>\n",
              "      <td>52.263803</td>\n",
              "      <td>43.036443</td>\n",
              "      <td>53.827523</td>\n",
              "      <td>44.277143</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.411131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.613201</td>\n",
              "      <td>0.195238</td>\n",
              "      <td>0.548347</td>\n",
              "      <td>0.394061</td>\n",
              "      <td>0.449799</td>\n",
              "      <td>0.253458</td>\n",
              "      <td>52.263803</td>\n",
              "      <td>43.036443</td>\n",
              "      <td>53.827523</td>\n",
              "      <td>44.277143</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.411131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.272266       0.222710  0.433175    0.385315  0.329507      0.273314   \n",
              "1   0.613201       0.195238  0.548347    0.394061  0.449799      0.253458   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var    aug  \\\n",
              "0  52.263803     43.036443     53.827523         44.277143  Width   \n",
              "1  52.263803     43.036443     53.827523         44.277143  Width   \n",
              "\n",
              "          dataset  val acc       acc  \n",
              "0  SP_the_wave120      0.0  3.411131  \n",
              "1  SP_the_wave120      0.0  3.411131  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3X0w3KxszDT",
        "outputId": "5d08efaf-1186-4adf-d95c-38d6faaa0136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(2)\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np \n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import sys\n",
        "import shutil\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from numpy.random import seed\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "import sklearn\n",
        "import datetime, os\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.regularizers import l2\n",
        "import os\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import datetime as datetime\n",
        "import tensorflow\n",
        "from skimage import transform as tf\n",
        "import random\n",
        "from keras.regularizers import l2\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define Callback function for early stopping and tensorboard\n",
        "earlystop=EarlyStopping(patience=3)\n",
        "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                        ,patience=3\n",
        "                                        ,verbose=0\n",
        "                                        ,factor=0.5\n",
        "                                        ,min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "# from keras.applications.vgg16 import VGG16\n",
        "# model = VGG16()\n",
        "\n",
        "\n",
        "def load_data_training_and_test(datasetname):\n",
        "        npzfile=np.load(path+datasetname+'training_data.npz')\n",
        "        train=npzfile['arr_0']\n",
        "        \n",
        "\n",
        "        npzfile=np.load(path+datasetname+'training_labels.npz')\n",
        "        train_labels=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_data.npz')\n",
        "        test=npzfile['arr_0']\n",
        "\n",
        "        npzfile=np.load(path+datasetname+'testing_labels.npz')\n",
        "        test_labels=npzfile['arr_0']    \n",
        "        return (train,train_labels),(test,test_labels)\n",
        "\n",
        "(x_train,y_train),(x_test,y_testing)=load_data_training_and_test(Dataset[0])\n",
        "\n",
        "\n",
        "y_train=y_train.reshape(y_train.shape[0],1)\n",
        "y_testing=y_testing.reshape(y_testing.shape[0],1)\n",
        "\n",
        "x_train=x_train.astype('float32')\n",
        "x_test=x_test.astype('float32')\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255\n",
        "training_size=len(x_train)\n",
        "test_size=len(y_testing)\n",
        "classes = np.unique(y_train)\n",
        "nClasses = len(classes)\n",
        "num_classes = len(classes)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed())\n",
        "cvscores = []\n",
        "cvscores1 = []\n",
        "precision0=[]\n",
        "precision1=[]\n",
        "recall0=[]\n",
        "recall1=[]\n",
        "f1_score0=[]\n",
        "f1_score1=[]\n",
        "f11=[]\n",
        "X = x_train\n",
        "Y =y_train\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "      model=Sequential()\n",
        "      model.add(Conv2D(40, (9, 9), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001), input_shape=x_train.shape[1:]))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(3,3))\n",
        "\n",
        "      model.add(Conv2D(18, (5, 5), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "\n",
        "      model.add(Conv2D(8, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Conv2D(3, (3, 3), kernel_initializer=keras.initializers.glorot_uniform(seed=2), kernel_regularizer=l2(0.001)))\n",
        "      model.add(Activation('relu'))\n",
        "      model.add(MaxPooling2D(2,2))\n",
        "\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(64,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(32,activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "      model.add(Dense(2,activation='softmax'))\n",
        "      from keras.optimizers import SGD\n",
        "      opt = SGD(lr=0.00001)\n",
        "      optimizer = keras.optimizers.Adam(lr=0.00001)\n",
        "      model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "      \n",
        "      \n",
        "      datagen = ImageDataGenerator(height_shift_range=(random.uniform(0.1,0.9)))\n",
        "      val_datagen = ImageDataGenerator(height_shift_range=(random.uniform(0.1,0.9)))\n",
        "\n",
        "      earlystop=EarlyStopping(patience=5)\n",
        "      learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy'\n",
        "                                              ,patience=5\n",
        "                                              ,verbose=0\n",
        "                                              ,factor=0.5\n",
        "                                              ,min_lr=0.00001)\n",
        "\n",
        "      callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "\n",
        "      epochs=50\n",
        "\n",
        "      mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "\n",
        "      train_generator = datagen.flow(X[train],Y[train],batch_size=batch_size)\n",
        "      validation_generator = val_datagen.flow(X[test],Y[test],batch_size=batch_size)\n",
        "\n",
        "      history=model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs,\n",
        "            validation_data=validation_generator,\n",
        "            verbose=0,\n",
        "            shuffle=True\n",
        "            ,callbacks=callbacks)\n",
        "      \n",
        "            \n",
        "\n",
        "      predicted_classes = model.predict(x_test)\n",
        "      predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "\n",
        "\n",
        "      target_names = [\"0\",\"1\"]\n",
        "      a=classification_report(y_testing, predicted_classes, target_names=target_names,output_dict=True)\n",
        "      model.fit(train_generator, epochs=10, batch_size=32, verbose=0)\n",
        "      scores = model.evaluate(train_generator, verbose=0)\n",
        "      scores1 = model.evaluate(validation_generator, verbose=0)\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      cvscores1.append(scores1[1] * 100)\n",
        "      precision0.append(a['0']['precision'])\n",
        "      precision1.append(a['1']['precision'])\n",
        "      recall0.append(a['0']['recall'])\n",
        "      recall1.append(a['1']['recall'])\n",
        "      f1_score0.append(a['0']['f1-score'])\n",
        "      f1_score1.append(a['1']['f1-score'])\n",
        "\n",
        "df=[numpy.mean(precision0),numpy.mean(precision1)]\n",
        "df=pd.DataFrame(df)\n",
        "df.columns = ['precision']\n",
        "df['Precision var']=[numpy.std(precision0),numpy.std(precision1)]\n",
        "df['recall']=[numpy.mean(recall0),numpy.mean(recall1)]\n",
        "df['recall var']=[numpy.std(recall0),numpy.std(recall1)]\n",
        "df['f1-score']=[numpy.mean(f1_score0),numpy.mean(f1_score1)]\n",
        "df['f1-score var']=[numpy.std(f1_score0),numpy.std(f1_score1)]\n",
        "df['Accuracy']=[numpy.mean(cvscores),numpy.mean(cvscores)]\n",
        "df['Accuracy var']=[numpy.std(cvscores),numpy.std(cvscores)]\n",
        "df['Val Accuracy']=[numpy.mean(cvscores1),numpy.mean(cvscores1)]\n",
        "df['Val Accuracy var']=[numpy.std(cvscores1),numpy.std(cvscores1)]\n",
        "df['aug']=['height','height']\n",
        "df['dataset']=[Dataset[0],Dataset[0]]\n",
        "df['val acc']=(history.history['val_accuracy'][-1])*100\n",
        "df['acc']=(history.history['accuracy'][-1])*100\n",
        "Results6=Results6.append(df)\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Results6)\n",
        "keras.backend.clear_session()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.267034</td>\n",
              "      <td>0.219428</td>\n",
              "      <td>0.387204</td>\n",
              "      <td>0.470942</td>\n",
              "      <td>0.255434</td>\n",
              "      <td>0.305381</td>\n",
              "      <td>38.633591</td>\n",
              "      <td>43.876056</td>\n",
              "      <td>39.001985</td>\n",
              "      <td>42.738629</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>100.0</td>\n",
              "      <td>99.401557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.435451</td>\n",
              "      <td>0.218315</td>\n",
              "      <td>0.614876</td>\n",
              "      <td>0.467446</td>\n",
              "      <td>0.447273</td>\n",
              "      <td>0.307355</td>\n",
              "      <td>38.633591</td>\n",
              "      <td>43.876056</td>\n",
              "      <td>39.001985</td>\n",
              "      <td>42.738629</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>100.0</td>\n",
              "      <td>99.401557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.267034       0.219428  0.387204    0.470942  0.255434      0.305381   \n",
              "1   0.435451       0.218315  0.614876    0.467446  0.447273      0.307355   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var     aug  \\\n",
              "0  38.633591     43.876056     39.001985         42.738629  height   \n",
              "1  38.633591     43.876056     39.001985         42.738629  height   \n",
              "\n",
              "          dataset  val acc        acc  \n",
              "0  SP_the_wave120    100.0  99.401557  \n",
              "1  SP_the_wave120    100.0  99.401557  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmZr1SEdOUxs"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mvmX_cKKmaC",
        "outputId": "b390ea6d-906d-4415-d102-49749414a220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "Final=pd.DataFrame([])\n",
        "Final=Final.append(Results)\n",
        "Final=Final.append(Results1)\n",
        "Final=Final.append(Results2)\n",
        "Final=Final.append(Results3)\n",
        "Final=Final.append(Results4)\n",
        "Final=Final.append(Results5)\n",
        "Final=Final.append(Results6)\n",
        "\n",
        "\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "display(Final)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>Precision var</th>\n",
              "      <th>recall</th>\n",
              "      <th>recall var</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>f1-score var</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Accuracy var</th>\n",
              "      <th>Val Accuracy</th>\n",
              "      <th>Val Accuracy var</th>\n",
              "      <th>aug</th>\n",
              "      <th>dataset</th>\n",
              "      <th>val acc</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.279470</td>\n",
              "      <td>0.228186</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.489898</td>\n",
              "      <td>0.381325</td>\n",
              "      <td>0.311351</td>\n",
              "      <td>60.023938</td>\n",
              "      <td>48.960492</td>\n",
              "      <td>59.952153</td>\n",
              "      <td>48.950806</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.213687</td>\n",
              "      <td>0.261711</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.489898</td>\n",
              "      <td>0.278561</td>\n",
              "      <td>0.341166</td>\n",
              "      <td>60.023938</td>\n",
              "      <td>48.960492</td>\n",
              "      <td>59.952153</td>\n",
              "      <td>48.950806</td>\n",
              "      <td>No Aug</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.459532</td>\n",
              "      <td>0.037440</td>\n",
              "      <td>0.636967</td>\n",
              "      <td>0.293680</td>\n",
              "      <td>0.504206</td>\n",
              "      <td>0.119854</td>\n",
              "      <td>66.917010</td>\n",
              "      <td>25.703386</td>\n",
              "      <td>68.348077</td>\n",
              "      <td>23.308606</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.478677</td>\n",
              "      <td>0.076398</td>\n",
              "      <td>0.349587</td>\n",
              "      <td>0.294166</td>\n",
              "      <td>0.339408</td>\n",
              "      <td>0.247404</td>\n",
              "      <td>66.917010</td>\n",
              "      <td>25.703386</td>\n",
              "      <td>68.348077</td>\n",
              "      <td>23.308606</td>\n",
              "      <td>HorizontalFlip</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.275028</td>\n",
              "      <td>0.224724</td>\n",
              "      <td>0.345972</td>\n",
              "      <td>0.370857</td>\n",
              "      <td>0.286590</td>\n",
              "      <td>0.253027</td>\n",
              "      <td>36.833034</td>\n",
              "      <td>36.789130</td>\n",
              "      <td>37.053457</td>\n",
              "      <td>36.802465</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.425736</td>\n",
              "      <td>0.212898</td>\n",
              "      <td>0.649174</td>\n",
              "      <td>0.369774</td>\n",
              "      <td>0.506446</td>\n",
              "      <td>0.260354</td>\n",
              "      <td>36.833034</td>\n",
              "      <td>36.789130</td>\n",
              "      <td>37.053457</td>\n",
              "      <td>36.802465</td>\n",
              "      <td>VerticalFlip</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.379242</td>\n",
              "      <td>0.190103</td>\n",
              "      <td>0.564455</td>\n",
              "      <td>0.463417</td>\n",
              "      <td>0.374018</td>\n",
              "      <td>0.303810</td>\n",
              "      <td>57.329335</td>\n",
              "      <td>44.965510</td>\n",
              "      <td>57.081340</td>\n",
              "      <td>46.729195</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>99.520385</td>\n",
              "      <td>94.254935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.642834</td>\n",
              "      <td>0.183221</td>\n",
              "      <td>0.435124</td>\n",
              "      <td>0.463158</td>\n",
              "      <td>0.335487</td>\n",
              "      <td>0.304394</td>\n",
              "      <td>57.329335</td>\n",
              "      <td>44.965510</td>\n",
              "      <td>57.081340</td>\n",
              "      <td>46.729195</td>\n",
              "      <td>Rotate</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>99.520385</td>\n",
              "      <td>94.254935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.252676</td>\n",
              "      <td>0.210750</td>\n",
              "      <td>0.296682</td>\n",
              "      <td>0.380216</td>\n",
              "      <td>0.239557</td>\n",
              "      <td>0.251700</td>\n",
              "      <td>29.073909</td>\n",
              "      <td>37.186501</td>\n",
              "      <td>31.503677</td>\n",
              "      <td>37.628919</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>44.604316</td>\n",
              "      <td>37.462598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.555884</td>\n",
              "      <td>0.055712</td>\n",
              "      <td>0.688430</td>\n",
              "      <td>0.374863</td>\n",
              "      <td>0.519799</td>\n",
              "      <td>0.261168</td>\n",
              "      <td>29.073909</td>\n",
              "      <td>37.186501</td>\n",
              "      <td>31.503677</td>\n",
              "      <td>37.628919</td>\n",
              "      <td>Shear</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>44.604316</td>\n",
              "      <td>37.462598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.272266</td>\n",
              "      <td>0.222710</td>\n",
              "      <td>0.433175</td>\n",
              "      <td>0.385315</td>\n",
              "      <td>0.329507</td>\n",
              "      <td>0.273314</td>\n",
              "      <td>52.263803</td>\n",
              "      <td>43.036443</td>\n",
              "      <td>53.827523</td>\n",
              "      <td>44.277143</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.411131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.613201</td>\n",
              "      <td>0.195238</td>\n",
              "      <td>0.548347</td>\n",
              "      <td>0.394061</td>\n",
              "      <td>0.449799</td>\n",
              "      <td>0.253458</td>\n",
              "      <td>52.263803</td>\n",
              "      <td>43.036443</td>\n",
              "      <td>53.827523</td>\n",
              "      <td>44.277143</td>\n",
              "      <td>Width</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.411131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.267034</td>\n",
              "      <td>0.219428</td>\n",
              "      <td>0.387204</td>\n",
              "      <td>0.470942</td>\n",
              "      <td>0.255434</td>\n",
              "      <td>0.305381</td>\n",
              "      <td>38.633591</td>\n",
              "      <td>43.876056</td>\n",
              "      <td>39.001985</td>\n",
              "      <td>42.738629</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.401557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.435451</td>\n",
              "      <td>0.218315</td>\n",
              "      <td>0.614876</td>\n",
              "      <td>0.467446</td>\n",
              "      <td>0.447273</td>\n",
              "      <td>0.307355</td>\n",
              "      <td>38.633591</td>\n",
              "      <td>43.876056</td>\n",
              "      <td>39.001985</td>\n",
              "      <td>42.738629</td>\n",
              "      <td>height</td>\n",
              "      <td>SP_the_wave120</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>99.401557</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   precision  Precision var    recall  recall var  f1-score  f1-score var  \\\n",
              "0   0.279470       0.228186  0.600000    0.489898  0.381325      0.311351   \n",
              "1   0.213687       0.261711  0.400000    0.489898  0.278561      0.341166   \n",
              "0   0.459532       0.037440  0.636967    0.293680  0.504206      0.119854   \n",
              "1   0.478677       0.076398  0.349587    0.294166  0.339408      0.247404   \n",
              "0   0.275028       0.224724  0.345972    0.370857  0.286590      0.253027   \n",
              "1   0.425736       0.212898  0.649174    0.369774  0.506446      0.260354   \n",
              "0   0.379242       0.190103  0.564455    0.463417  0.374018      0.303810   \n",
              "1   0.642834       0.183221  0.435124    0.463158  0.335487      0.304394   \n",
              "0   0.252676       0.210750  0.296682    0.380216  0.239557      0.251700   \n",
              "1   0.555884       0.055712  0.688430    0.374863  0.519799      0.261168   \n",
              "0   0.272266       0.222710  0.433175    0.385315  0.329507      0.273314   \n",
              "1   0.613201       0.195238  0.548347    0.394061  0.449799      0.253458   \n",
              "0   0.267034       0.219428  0.387204    0.470942  0.255434      0.305381   \n",
              "1   0.435451       0.218315  0.614876    0.467446  0.447273      0.307355   \n",
              "\n",
              "    Accuracy  Accuracy var  Val Accuracy  Val Accuracy var             aug  \\\n",
              "0  60.023938     48.960492     59.952153         48.950806          No Aug   \n",
              "1  60.023938     48.960492     59.952153         48.950806          No Aug   \n",
              "0  66.917010     25.703386     68.348077         23.308606  HorizontalFlip   \n",
              "1  66.917010     25.703386     68.348077         23.308606  HorizontalFlip   \n",
              "0  36.833034     36.789130     37.053457         36.802465    VerticalFlip   \n",
              "1  36.833034     36.789130     37.053457         36.802465    VerticalFlip   \n",
              "0  57.329335     44.965510     57.081340         46.729195          Rotate   \n",
              "1  57.329335     44.965510     57.081340         46.729195          Rotate   \n",
              "0  29.073909     37.186501     31.503677         37.628919           Shear   \n",
              "1  29.073909     37.186501     31.503677         37.628919           Shear   \n",
              "0  52.263803     43.036443     53.827523         44.277143           Width   \n",
              "1  52.263803     43.036443     53.827523         44.277143           Width   \n",
              "0  38.633591     43.876056     39.001985         42.738629          height   \n",
              "1  38.633591     43.876056     39.001985         42.738629          height   \n",
              "\n",
              "          dataset     val acc        acc  \n",
              "0  SP_the_wave120         NaN        NaN  \n",
              "1  SP_the_wave120         NaN        NaN  \n",
              "0  SP_the_wave120         NaN        NaN  \n",
              "1  SP_the_wave120         NaN        NaN  \n",
              "0  SP_the_wave120         NaN        NaN  \n",
              "1  SP_the_wave120         NaN        NaN  \n",
              "0  SP_the_wave120   99.520385  94.254935  \n",
              "1  SP_the_wave120   99.520385  94.254935  \n",
              "0  SP_the_wave120   44.604316  37.462598  \n",
              "1  SP_the_wave120   44.604316  37.462598  \n",
              "0  SP_the_wave120    0.000000   3.411131  \n",
              "1  SP_the_wave120    0.000000   3.411131  \n",
              "0  SP_the_wave120  100.000000  99.401557  \n",
              "1  SP_the_wave120  100.000000  99.401557  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}